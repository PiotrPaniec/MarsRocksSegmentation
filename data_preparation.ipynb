{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "real_data_path = Path(r\"C:/Users/Pulpit/Desktop/ml space/MarsData-MarsData-V2\")\n",
    "\n",
    "output_path = Path(r\"C:/Users/Pulpit/Desktop/ml space/MarsData-combined\")\n",
    "train_img_path = output_path / \"train\" / \"img\"\n",
    "train_mask_path = output_path / \"train\" / \"mask\"\n",
    "test_img_path = output_path / \"test\" / \"img\"\n",
    "test_mask_path = output_path / \"test\" / \"mask\"\n",
    "\n",
    "for folder in [train_img_path, train_mask_path, test_img_path, test_mask_path]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def split_and_copy(data_path, is_real, train_ratio=0.85):\n",
    "    images = sorted(data_path.glob(\"img/**/*.png\"))\n",
    "    masks = sorted(data_path.glob(\"label/**/*.png\"))\n",
    "\n",
    "    print(len(images), len(masks))\n",
    "    assert len(images) == len(masks), \"Mismatch between images and masks\"\n",
    "\n",
    "    data_pairs = list(zip(images, masks))\n",
    "    random.shuffle(data_pairs)\n",
    "\n",
    "    train_size = int(len(data_pairs) * train_ratio)\n",
    "\n",
    "    train_pairs = data_pairs[:train_size]\n",
    "    test_pairs = data_pairs[train_size:] if is_real else []\n",
    "\n",
    "    for img_path, mask_path in train_pairs:\n",
    "        shutil.copy(img_path, train_img_path / img_path.name)\n",
    "        shutil.copy(mask_path, train_mask_path / mask_path.name)\n",
    "\n",
    "    for img_path, mask_path in test_pairs:\n",
    "        shutil.copy(img_path, test_img_path / img_path.name)\n",
    "        shutil.copy(mask_path, test_mask_path / mask_path.name)\n",
    "\n",
    "split_and_copy(real_data_path, is_real=True)\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "base_path = r\"C:\\Users\\Pulpit\\Desktop\\ml space\\SynMars-master\"\n",
    "output_path = r\"C:\\Users\\Pulpit\\Desktop\\ml space\\MarsData-combined\"\n",
    "\n",
    "train_img_path = os.path.join(output_path, \"train\", \"img\")\n",
    "train_mask_path = os.path.join(output_path, \"train\", \"mask\")\n",
    "\n",
    "os.makedirs(train_img_path, exist_ok=True)\n",
    "os.makedirs(train_mask_path, exist_ok=True)\n",
    "\n",
    "routes = [f\"route{i}\" for i in range(1, 7)]\n",
    "\n",
    "for route in routes:\n",
    "    img_folder = os.path.join(base_path, route, \"img\")\n",
    "    mask_folder = os.path.join(base_path, route, \"mask\")\n",
    "\n",
    "    img_files = sorted(os.listdir(img_folder))\n",
    "    mask_files = sorted(os.listdir(mask_folder))\n",
    "\n",
    "    assert len(img_files) == len(mask_files), f\"Mismatch in {route}: {len(img_files)} images, {len(mask_files)} masks\"\n",
    "\n",
    "    for img, mask in zip(img_files, mask_files):\n",
    "        shutil.copy(os.path.join(img_folder, img), os.path.join(train_img_path, img))\n",
    "        shutil.copy(os.path.join(mask_folder, mask), os.path.join(train_mask_path, mask))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_files_in_directory(directory, prefix):\n",
    "    files = sorted(os.listdir(directory))\n",
    "    for i, filename in enumerate(files):\n",
    "        new_name = f\"{prefix}_{i+1:04d}.png\"\n",
    "        os.rename(os.path.join(directory, filename), os.path.join(directory, new_name))\n",
    "\n",
    "base_dir = r\"C:\\Users\\Pulpit\\Desktop\\ml space\\MarsData-combined\"\n",
    "sub_dirs = [\"train/img\", \"train/mask\", \"test/img\", \"test/mask\"]\n",
    "\n",
    "for sub_dir in sub_dirs:\n",
    "    full_path = os.path.join(base_dir, sub_dir)\n",
    "    prefix = sub_dir.replace(\"/\", \"_\")\n",
    "    rename_files_in_directory(full_path, prefix)\n",
    "\n",
    "print(\"Renaming Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was used to pad images to a certain size, but it is not a good approach\n",
    "\n",
    "# import os\n",
    "# from PIL import Image, ImageOps\n",
    "\n",
    "# folder_path_1 = r\"C:\\Users\\Pulpit\\Desktop\\ml space\\MarsData-combined\\train\\img\"\n",
    "# folder_path_2 = r\"C:\\Users\\Pulpit\\Desktop\\ml space\\MarsData-combined\\train\\mask\"\n",
    "# folder_path_3 = r\"C:\\Users\\Pulpit\\Desktop\\ml space\\MarsData-combined\\test\\img\"\n",
    "# folder_path_4 = r\"C:\\Users\\Pulpit\\Desktop\\ml space\\MarsData-combined\\test\\mask\"\n",
    "\n",
    "# folder_paths = [folder_path_1, folder_path_2, folder_path_3, folder_path_4]\n",
    "\n",
    "# target_width = 1920\n",
    "# target_height = 1080\n",
    "\n",
    "# for folder in folder_paths:\n",
    "#     for filename in os.listdir(folder):\n",
    "#         if filename.endswith(\".png\"):\n",
    "#             file_path = os.path.join(folder, filename)\n",
    "            \n",
    "#             img = Image.open(file_path)\n",
    "#             original_width, original_height = img.size\n",
    "\n",
    "#             if original_width < target_width or original_height < target_height:\n",
    "#                 left_padding = (target_width - original_width) // 2\n",
    "#                 top_padding = (target_height - original_height) // 2\n",
    "#                 right_padding = target_width - original_width - left_padding\n",
    "#                 bottom_padding = target_height - original_height - top_padding\n",
    "\n",
    "#                 padding = (left_padding, top_padding, right_padding, bottom_padding)\n",
    "#                 img_with_padding = ImageOps.expand(img, border=padding, fill=(0, 0, 0))\n",
    "                \n",
    "#                 img_with_padding.save(file_path)\n",
    "#                 print(f\"Padded: {filename}\")\n",
    "#             else:\n",
    "#                 print(f\"Already sufficient size: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torchvision.transforms as tv\n",
    "\n",
    "def serialize_dataset(dataset_path, target_path):\n",
    "    images_path = os.path.join(dataset_path, \"img\")\n",
    "    masks_path = os.path.join(dataset_path, \"mask\")\n",
    "    image_files = sorted(os.listdir(images_path))\n",
    "    mask_files = sorted(os.listdir(masks_path))\n",
    "\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "    for img_file, mask_file in zip(image_files, mask_files):\n",
    "        img = Image.open(os.path.join(images_path, img_file)).convert(\"RGB\")\n",
    "        mask = Image.open(os.path.join(masks_path, mask_file)).convert(\"L\")\n",
    "\n",
    "        transform_image = tv.transforms.Compose([\n",
    "            # tv.transforms.Resize((1080, 1920)), # in v3 version we mix images with different sizes\n",
    "            tv.transforms.ToTensor(),\n",
    "            tv.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "        transform_mask = tv.transforms.Compose([\n",
    "            # tv.transforms.Resize((1080, 1920)),\n",
    "            tv.transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        data = {\n",
    "            \"image\": transform_image(img),\n",
    "            \"mask\": transform_mask(mask)\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(target_path, f\"{img_file}.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "main_path = r\"C:\\Users\\Pulpit\\Desktop\\ml space\\MarsData-combined\"\n",
    "\n",
    "train_dataset_path = os.path.join(main_path, \"train\")\n",
    "test_dataset_path = os.path.join(main_path, \"test\")\n",
    "\n",
    "serialize_dataset(train_dataset_path, os.path.join(main_path, \"serialized_train\"))\n",
    "serialize_dataset(test_dataset_path, os.path.join(main_path, \"serialized_test\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
